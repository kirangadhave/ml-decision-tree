\newpage
\section{Decision Lists (For CS 6350 students)}
\label{sec:decision-lists}

\newtheorem*{theorem}{Theorem}

\begin{theorem}
Any 1-decision list is a linearly separable function.
\end{theorem}

\begin{proof}
We will prove the above statement by induction on terms in decision list. Let us assume that any 1-decision list is a linearly seperable function.\\
Let's consider the base case with only one term $x_1$. For now we assume $x_1$ is non negated. We have four different decision lists possible for this scenario. We will select a weight vector $\boldsymbol w$ and bias $b$ for each of the case, hence representing the decision list as a linearly separable function.
\begin{enumerate}
\item $(x_1, 1), (T, 1)$\\
$\boldsymbol w = [2]$\\
$b = 1$\\
We get,
$$ 2x_1 + 1 > 0 $$

\item $(x_1, 1), (T, 0)$\\
$\boldsymbol w = [2]$\\
$b = -1$\\
We get,
$$ 2x_1 - 1 > 0 $$

\item $(x_1, 0), (T, 1)$\\
$\boldsymbol w = [-2]$\\
$b = 1$\\
We get,
$$ -2x_1 + 1 > 0 $$

\item $(x_1, 0), (T, 0)$\\
$\boldsymbol w = [-2]$\\
$b = -1$\\
We get,
$$ -2x_1 - 1 > 0 $$
\end{enumerate}

In case $x_1$ is negated, we can replace $x_1$ in the equation with $(1-x_1)$. So our assumption is true for our base case with one term in decision tree. 
Now lets assume that any 1-decision list with $n$ terms is also a linearly separable function. Suppose we have a 1-decision list with $n+1$ terms,
$$f = (a_1, c_1), (a_2,c_2), (a_3,c_3), ..... ,(a_{n+1}, c_{n+1})$$
By induction hypothesis the decision list
$$(a_2,c_2), (a_3,c_3), ..... ,(a_{n+1},c_{n+1})$$ of length $n$ is a linearly separable function. Let it be represeted by weight vector $\boldsymbol w$ and bias $b$. Let $||w||_1 = \sum_{i=1}^{n} |w_i|$ be the 1-norm of $\boldsymbol w$. There are now four different values the first term $(a_1, c_1)$ can take as follows: $(x_1, 1),(x_1, 0),(\bar{x_1}, 1),(\bar{x_1},0)$.\\
Let $e_1 = [1,0,0,0....0]$ be a vector and $A = ||w|| + |b| + 1$. Now we claim that decision list $f$ is a linearly separable function represented by weight vector $w'$ and bias $b'$ where,
$$w' = w + Ae_1, \ b' = b$$
$$w' = w - Ae_1, \ b' = b$$
$$w' = w - Ae_1, \ b' = b - A$$
$$w' = w + Ae_1, \ b' = b - A$$
To verify our claim let us consider case where $(a_1, c_1)$ takes the form $(x_1, 1)$. For $x \in \{0, 1\}^n$.

$$\langle w', x \rangle = \langle w + Ae_1, x \rangle = \langle w,x \rangle + Ax_1$$
Now,
$$\langle w', x \rangle \geq b' = b$$
$$ \langle w,x \rangle + Ax_1 \geq b$$
If $x_1 = 1$ we have, $ \langle w,x \rangle - A \geq b$\\
$$ \langle w,x \rangle + ||w|| + |b| + 1 \geq b$$
$$ \langle w,x \rangle \geq - ||w|| - 1$$
Now, $||w|| + 1 > ||w||$
$$ \langle w,x \rangle > -||w||$$ Above statement is true for $x \in \{1,0\}^n$, so output of the function is $1$. Now consider $x_1 = 0$, we have
$$\langle w,x \rangle \geq b$$
By inductive hypothesis the decision list,
$$f' = (a_2,c_2), (a_3,c_3), ..... ,(a_{n+1},c_{n+1})$$
is linearly separable function with weight vector $\boldsymbol w$ and bias $b$. Hence output of the linear separable equation is $1$ only when output of decision list $f'$ is $1$, which is how $f$ calculates its output when $x_1 = 0$. we can say $f$ is indeed a linearly separable function. Other claims can be verified in a similar manners.





\end{proof}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "hw"
%%% End:
